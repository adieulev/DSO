{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"https://exed.polytechnique.edu/fr\" ><img src=\"https://exed.polytechnique.edu/sites/all/themes/college/images/logo.png\" style=\"float:left; max-width: 360px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"float:right; max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# [Scénarios d'Apprentissage Statistique](https://github.com/wikistat/Apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRC: Score d'appétence d'un produit bancaire  en <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a> avec <a href=\"http://scikit-learn.org/stable/#\"><img src=\"http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" style=\"max-width: 100px; display: inline\" alt=\"Scikit-learn\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résumé\n",
    "Les données sont composées de 825 clients d'une banque décrits par 32 variables concernant leurs avoirs, et utilisations de leurs comptes. Après avoir réalisé, avec [R](https://github.com/wikistat/Exploration/blob/master/GRC-carte_Visa/Explo-R-Visa.ipynb) ou [Python](https://github.com/wikistat/Exploration/blob/master/GRC-carte_Visa/Explo-Python-Visa.ipynb), le premier objectif de segmentation ou profilage des types de comportement des clients, le 2ème consiste à estimer puis prévoir un *score d'appétence* pour un produit bancaie, ici la carte visa premier. Comparaison des différentes méthodes et algorihtmes d'apprentissage pour atteindre cet objectif de la régression logistique au *boosting* (*extrem gradient*) en passant par les arbres, les SVM ou random forest. Une procédure de validation croisée généralisée est itérée sur une selection de ces méthodes. Celles d'agrégation de modèles conduisent aux meilleurs résultats. \n",
    "\n",
    "## Introduction\n",
    "### Objectif\n",
    "Un  [calepin]((https://github.com/wikistat/Exploration/blob/master/GRC-carte_Visa/Explo-Python-Visa.ipynb), qu'il est préférable d'exécuter préalablement, décrit le premier objectif d'exploration puis segmentation ou profilage des types de comportement des clients d'une banque. \n",
    "\n",
    "Ce deuxième calepin propose de construire un [score d'appétence](http://www.math.univ-toulouse.fr/~besse/Wikistat/pdf/st-scenar-app-visa.pdf) pour la carte *Visa Premier*. Il s'agit d'un score d'appétence mais ce pourrait être le score d'attrition (*churn*) d'un opérateur téléphonique ou encore un score de défaillance d'un emprunteur ou de faillite d'une entreprise; les outils de modélisation sont les mêmes et sont très largement utilisés dans tout le secteur tertiaire pour l'aide à la décision.\n",
    "\n",
    "### Présentation des données\n",
    "#### Les variables\n",
    "La liste des variables est issue d'une base de données retraçant l'historique mensuel bancaire et les caractéristiques de tous les clients. Un sondage a été réalisé afin d'alléger les traitements ainsi qu'une première sélection de variables. Les variables contenues dans le fichier initial sont décrites dans le tableau ci-dessous. Elles sont observées sur 1425 clients.\n",
    "\n",
    "*Tableau: Liste des variables initiales et de leur libellé* Attention, certains sont écrits en majuscules dans les programmes puis en minuscules après transfomation des données (logarithme, recodage) au cours d ela phase d'exploration. Les noms des variables logarithmes des variables quantitatives se terminent par `L`les variables qualitatives se terminent par `Q`ou `q`. \n",
    "\n",
    "**Identifiant** | **Libellé**\n",
    "           --|--\n",
    "`sexeq` | Sexe (qualitatif) \n",
    "`ager` | Age en années\n",
    "`famiq` | Situation familiale: `Fmar Fcel Fdiv Fuli Fsep Fveu`\n",
    "`relat` | Ancienneté de relation en mois\n",
    "`pcspq` | Catégorie socio-professionnelle (code num)\n",
    "`opgnb` | Nombre d'opérations par guichet dans le mois\n",
    "`moyrv` | Moyenne des mouvements nets créditeurs des 3 mois en Kf\n",
    "`tavep` | Total des avoirs épargne monétaire en francs\n",
    "`endet` | Taux d'endettement\n",
    "`gaget` | Total des engagements en francs\n",
    "`gagec` | Total des engagements court terme en francs\n",
    "`gagem` | Total des engagements moyen terme en francs\n",
    "`kvunb` | Nombre de comptes à vue\n",
    "`qsmoy` | Moyenne des soldes moyens sur 3 mois\n",
    "`qcred` | Moyenne des mouvements créditeurs en Kf\n",
    "`dmvtp` | Age du dernier mouvement (en jours)\\hline\n",
    "`boppn` | Nombre d'opérations à M-1\n",
    "`facan` | Montant facturé dans l'année en francs\n",
    "`lgagt` | Engagement long terme\n",
    "`vienb` | Nombre de produits contrats vie\n",
    "`viemt` | Montant des produits contrats vie en francs\n",
    "`uemnb` | Nombre de produits épargne monétaire\n",
    "`xlgnb` | Nombre de produits d'épargne logement\n",
    "`xlgmt` | Montant des produits d'épargne logement en francs\n",
    "`ylvnb` | Nombre de comptes sur livret\n",
    "`ylvmt` | Montant des comptes sur livret en francs\n",
    "`rocnb` | Nombre de paiements par carte bancaire à M-1\n",
    "`nptag` | Nombre de cartes point argent\n",
    "`itavc` | Total des avoirs sur tous les comptes\n",
    "`havef` | Total des avoirs épargne financière en francs\n",
    "`jnbjd | Nombre de jours à débit à M\n",
    "**`carvp`** | **Possession de la carte VISA Premier**\n",
    "\n",
    "\n",
    "**Répondre aux questions en s'aidant des résultats des exécutions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données\n",
    "### Lecture \n",
    "Les données sont disponibles dans le répertoire de ce calepin et chargées en même temps. Elles sont issues de la première phase de [prétraitement](https://github.com/wikistat/Exploration/blob/master/GRC-carte_Visa/Explo-R-Visa.ipynb) ou *data munging* pour détecter, corriger les erreurs et incohérences, éliminer des redondances, traiter les données manquantes, transformer certaines variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importation des librairies.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_config = {\n",
    "    'session_name': 'Visa-ML',\n",
    "    'session_owner': 'aymeric',\n",
    "    'sender_name': input(\"Your name:\"),\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture d'un data frame en ligne\n",
    "! wget -q https://raw.githubusercontent.com/adieulev/DSO/master/vispremv.dat\n",
    "vispremv = pd.read_table('vispremv.dat', delimiter=' ')\n",
    "\n",
    "#Donner la taille des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lecture d'un data frame si vous travaillez en local \n",
    "# Placer la table dans le bon dossier et décommenter la ligne suivante\n",
    "# vispremv = pd.read_table('vispremv.dat', delimiter=' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vispremv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Isoler les Variables quantitatives\n",
    "\n",
    "##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifier ci-dessous que la plupart des variables ont deux versions, l'une quantitative et l'autre qualitative.\n",
    "\n",
    "Les variables qualitatives (sexe, csp, famille) sont transformées en indicatrices à l'exception de la cible `CARVP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vispremv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformation en indicatrices des variables qualitatives\n",
    "# Utiliser pd.get_dummies\n",
    "\n",
    "\n",
    "#TODO\n",
    "\n",
    "# Concaténation ensuite avec les variables numériques\n",
    "# pd.concat([vispremDum,vispremNum],axis=1)\n",
    "\n",
    "#TODO\n",
    "\n",
    "send('Dummy vairable done', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Combien d'individus et combien de variables sont finalement concernés? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO calculer nombre individus et variables\n",
    "\n",
    "send(np.array(vispremR.shape), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# La variable à expliquer est recodée\n",
    "y=vispremv[\"CARVP\"].map(lambda x: 0 if x==\"Cnon\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des échantillons apprentissage et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rd_seed=111 # Modifier cette valeur d'initialisation\n",
    "npop=len(vispremv)\n",
    "#TODO trouver xApp,xTest,yApp,yTest a laide de train_test_split\n",
    "#On placera 200 points dans l'ensmeble de test\n",
    "\n",
    "send(np.array(xApp.shape), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Régression logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf)\n",
    "Cette ancienne méthode reste toujours très utilisée. D'abord par habitude mais aussi par efficacité pour le traitement de données très volumineuses lors de l'estimation de très gros modèles (beaucoup de variables) notamment par exemple chez Criteo ou CDiscount.\n",
    "\n",
    "### Estimation et optimisation\n",
    "La procédure de sélection de modèle est celle par pénalisation: *ridge*, Lasso ou une combinaison (*elastic net*). Contrairement aux procédures disponibles en R (*stepwise, backward, forward*) optimisant un critère comme *AIC*, l'algorithme proposé dans `scikit-learn` nepermet pas une prise en compte simple des interactions. D'autre part les compléments usuels (test de Wald ou du rapport de vraisemblance) ne sont pas directement fournis. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarque importante: \n",
    "\n",
    "POur la cross validation, doit on couper le **dataset complet** en train + validation sets ou bien seulement **l'ensemble d'apprentissage**?\n",
    "\n",
    "A première vue, on pourrait donner le dataset entier, car on va déjà dans la cross validation couper en deux, mais en fait il faut couper en trois:\n",
    "- un test set qu'on réserve \n",
    "- un ensemble d'apprentissage sur lequel on fait de la validation croisée (donc qu'on va couper de nombreuses fois en un train set + un validation set)\n",
    "\n",
    "Sinon, comme on va choisir le paramètre qui a le meilleur résultat sur l'ensemble de validation (ou qui a le meilleur résultat après cross validation), il est possible qu'on choisisse un paramètre pour lequel le score était particuliérement bon \"par chance\".\n",
    "\n",
    "On évaluera toujours en dernier lieu la performance sur un dataset (le test) complètement indépendant du processus de sélection des paramètres (le train) ou hyperparamètres (le validation).\n",
    "\n",
    "C'est ce qui apparaissait dans le pipeline au premier cours !\n",
    "\n",
    "<center>\n",
    "<img src=\"http://www.cmap.polytechnique.fr/~aymeric.dieuleveut/papers/This-is-ML-pipe\" style=\"float:left; max-width: 600px; display: inline\" alt=\"INSA\"/></center>\n",
    "<br>\n",
    "\n",
    "\n",
    "Voir par exemple: https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation *ridge*\n",
    "On considère maintenant l'optimisation Ridge, ou la pénalité est proportionnelle à la norme 2 de l'estimateur (au carré)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grilles de valeurs du paramètre de pénalisation\n",
    "param=[{\"C\":[0.5,1,5,10,12,15,30]}]\n",
    "# TODO\n",
    "# 1. Definir le modèle (regression logistique)\n",
    "# 2. On utilisera ici une pénalité l1 penalty=\"l2\"\n",
    "# 3. Utiliser GridSearchCV pour obtenir directement le meilleur paramètre de régularisation\n",
    "# 4. On appellera la méthode logitRidge pour la suite ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calcul erreur\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" %\n",
    "      (1. - logitRidge.best_score_, logitRidge.best_params_))\n",
    "send((\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - logitRidge.best_score_, logitRidge.best_params_)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prévision\n",
    "yChap = logitRidge.predict(xTest)\n",
    "\n",
    "#Todo matrice de confusion\n",
    "\n",
    "\n",
    "# Erreur sur l'échantillon test\n",
    "print(\"Erreur de test régression Ridge = %f\" % (1-logitRidge.score(xTest, yTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Noter l'erreur de prévision; Comparer avec celle estimée par validation croisée.\n",
    "\n",
    "### Interprétation\n",
    "\n",
    "L'objet logitRidge issu de GridSearchCV ne retient pas les paramètres estimés dans le modèle. Il faut donc ré-estimer avec la valeur optimale du paramètre de pénalisation si l'on souhaite afficher ces coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeOpt=LogisticRegression(penalty=\"l2\",C=12) # replace by the best parameters !!\n",
    "RidgeOpt=LassoOpt.fit(xApp, yApp)\n",
    "# Récupération des coefficients\n",
    "vect_coef=np.matrix.transpose(LassoOpt.coef_)\n",
    "vect_coef=vect_coef.ravel()\n",
    "#Affichage des 25 plus importants\n",
    "coef=pd.Series(abs(vect_coef),index=xApp.columns).sort_values(ascending=False)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "coef.plot(kind='bar')\n",
    "plt.title('Coeffients')\n",
    "plt.tight_layout()\n",
    "send(plt, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelles sont les variables importantes? Comment interpréter?\n",
    "\n",
    "**Q** La pénalisation Lasso est-elle effective?\n",
    "\n",
    "Il serait intéressant de comparer acec les versions *ridge* et *elestic net* d'optiisation du modèle.\n",
    "\n",
    "### Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "listMethod=[[\"Lasso\",logitLasso],[\"Ridge\",logitRidge]]\n",
    "\n",
    "for method in enumerate(listMethod):\n",
    "    probas_ = method[1][1].predict_proba(xTest)\n",
    "    fpr, tpr, thresholds = roc_curve(yTest, probas_[:,1])\n",
    "    plt.plot(fpr, tpr, lw=1,label=\"%s\"%method[1][0])\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.legend(loc=\"best\")\n",
    "send(plt, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse discriminante\n",
    "Trois méthodes sont disponibles: paramétrique linéaire ou quadratique et non paramétrique (*k* plus proches voisins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import discriminant_analysis\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicriminante linéaire\n",
    "Estimation du modèle; il n'y a pas de procédure de sélection de variables proposées. Puis prévision de l'échantillon test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. definir la methode 'lda' comme discriminant_analysis.LinearDiscriminantAnalysis\n",
    "\n",
    "# 2. fitter la méthode\n",
    "\n",
    "# 3. Prédire sur  l'échantillon test\n",
    "\n",
    "# 4. Calculer la matrice de confusion\n",
    "\n",
    "\n",
    "# Erreur de prévision sur le test\n",
    "print(\"Erreur de test lda = %f\" % (1-disLin.score(xTest,yTest)))\n",
    "send((\"Erreur de test lda = %f\" % (1-disLin.score(xTest,yTest))), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire de la qualité? Des possibilités d'interprétation?\n",
    "\n",
    "**Q** Que signifie le *warning*? Quelles variables osnt en cause?\n",
    "### Discriminante quadratique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Procéder de même pour QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. Définition du modèle avec 10 plus proches voisins (utiliser KNeighborsClassifier)\n",
    "\n",
    "# 2. Fitter\n",
    "# 3. Prévision de l'échantillon test\n",
    "\n",
    "# 4. matrice de confusion\n",
    "\n",
    "print(table)\n",
    "# Erreur de prévision sur le test\n",
    "print(\"Erreur de test knn = %f\" % (1-disKnn.score(xTest,yTest)))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optimisation du paramètre de complexité (nombre de voisins) k\n",
    "#Grille de valeurs\n",
    "param_grid=[{\"n_neighbors\":list(range(1,15))}]\n",
    "disKnn=GridSearchCV(KNeighborsClassifier(),param_grid,cv=5,n_jobs=-1)\n",
    "disKnnOpt=disKnn.fit(xApp, yApp) # GridSearchCV est lui même un estimateur\n",
    "# paramètre optimal\n",
    "disKnnOpt.best_params_[\"n_neighbors\"]\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1.-disKnnOpt.best_score_,disKnnOpt.best_params_))\n",
    "send((\"Meilleur score = %f, Meilleur paramètre = %s\" % (1.-disKnnOpt.best_score_,disKnnOpt.best_params_)), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prévision de l'échantillon test\n",
    "yChap = disKnnOpt.predict(xTest)\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(yChap,yTest)\n",
    "print(table)\n",
    "\n",
    "# Estimation de l'erreur de prévision sur l'échantillon test\n",
    "print(\"Erreur de test knn_opt = %f\" % (1-disKnnOpt.score(xTest,yTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "# Liste des méthodes\n",
    "listMethod=[[\"lda\",disLin],[\"qda\",disQua],[\"knn\",disKnnOpt]]\n",
    "# Tracé des courbes\n",
    "for method in enumerate(listMethod):\n",
    "    probas_ = method[1][1].predict_proba(xTest)\n",
    "    fpr, tpr, thresholds = roc_curve(yTest, probas_[:,1])\n",
    "    plt.plot(fpr, tpr, lw=1,label=\"%s\"%method[1][0])\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Arbres binaires de décision](http://wikistat.fr/pdf/st-m-app-cart.pdf)\n",
    "Les arbres binaires de décision concurrencent la régression logistique et gardent une place de choix dans les services de Gestion de la Relation Client, maintenant de *Science des Données*, par la facilité d'interprétation des modèles qui en découlent. L'optimisation de la complexité d'un artbre peut être délicate à opérer cr très sensible aux fluctuations de l'échantillon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# définition et fit du modèle\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quel est le critère d'homogénéité des noeuds utilisé par défaut?\n",
    "\n",
    "**Q** Quel est le problème concernant l'élagage de l'arbre dans `Scikkit-learn` vis à vis des possibliités de la librairie `rpart` de R?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimisation de la profondeur de l'arbre\n",
    "#TODO\n",
    "\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - treeOpt.best_score_,treeOpt.best_params_))\n",
    "send((\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - treeOpt.best_score_,treeOpt.best_params_)), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prévision de l'échantillon test\n",
    "yChap = treeOpt.predict(xTest)\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(yChap,yTest)\n",
    "print(table)# Erreur de prévision sur le test\n",
    "print(\"Erreur de test tree qualitatif = %f\" % (1-treeOpt.score(xTest,yTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydotplus\n",
    "treeG=DecisionTreeClassifier(max_depth=treeOpt.best_params_['max_depth'])\n",
    "treeG.fit(xApp,yApp)\n",
    "dot_data = StringIO() \n",
    "export_graphviz(treeG, out_file=dot_data) \n",
    "graph=pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_png(\"treeOpt.png\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='treeOpt.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Courbes ROC](http://wikistat.fr/pdf/st-m-app-risque.pdf)\n",
    "Comparaison des méthodes précédentes.\n",
    "\n",
    "La valeur de seuil par défaut (0.5) n'étant pas nécessairement celle \"optimale\", il est important de comparer les courbes ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Liste des méthodes\n",
    "listMethod=[[\"Logit\",logitLasso],[\"lda\",disLin],[\"Arbre\",treeOpt]]\n",
    "# Tracé des courbes\n",
    "for method in enumerate(listMethod):\n",
    "    probas_ = method[1][1].predict_proba(xTest)\n",
    "    fpr, tpr, thresholds = roc_curve(yTest, probas_[:,1])\n",
    "    plt.plot(fpr, tpr, lw=1,label=\"%s\"%method[1][0])\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.legend(loc=\"best\")\n",
    "send(plt, 9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenter les résultats.\n",
    "\n",
    "**Q** Intérêt de la régression logistique par rapport à l'analyse discriminante linéaire?\n",
    "\n",
    "**Q** Conséquence du croisement des courbes ROC sur l'évaluation de l'AUC.\n",
    "\n",
    "L'échantillon test reste de taille modeste (200). une étude plus systématique est nécessaire ainsi que la prise en compte des autres méthodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Algorithmes d'agrégation de modèles](http://wikistat.fr/pdf/st-m-app-agreg.pdf)\n",
    "Il s'agit de comparer les principaux algorithmes issus de l'apprentissage machine: *bagging, random forest, boosting*.\n",
    "\n",
    "### *Bagging*\n",
    "\n",
    "**Q** Quel est par défaut l'estimateur qui est agrégé? \n",
    "\n",
    "**Q** Quel est le nombre d'estimateurs par défaut? Est-il nécessaire de l'optimiser?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag= # Def model (nestim =100)\n",
    "bagC=bag.fit(xApp, yApp)\n",
    "# Prévision de l'échantillon test\n",
    "yChap = bagC.predict(xTest)\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(yChap,yTest)\n",
    "print(table)\n",
    "\n",
    "# Erreur de prévision sur le test\n",
    "print(\"Erreur de test avec le bagging = %f\" % (1-bagC.score(xTest,yTest)))\n",
    "send((\"Erreur de test avec le bagging = %f\" % (1-bagC.score(xTest,yTest)), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Exécuter plusieurs fois la cellule ci-dessus. Que penser de la stabilité de l'estimation de l'erreur et donc de sa fiabilité?\n",
    "\n",
    "### *Random forest*\n",
    "\n",
    "**Q** Quel paramètre doit être optimisé pour cet algorithme? Quel est sa valeur par défaut?\n",
    "\n",
    "**Q** Le nombre d'arbres de la forêt est-il un paramètre sensible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimisation de max_features\n",
    "param=[{\"max_features\":list(range(2,10,1))}]\n",
    "\n",
    "rf= # TODO DEF gridsearchCV\n",
    "rfOpt=rf.fit(xApp, yApp)\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - rfOpt.best_score_,rfOpt.best_params_))\n",
    "send((\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - rfOpt.best_score_,rfOpt.best_params_)), 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prévision de l'échantillon test\n",
    "yChap = rfOpt.predict(xTest)\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(yChap,yTest)\n",
    "print(table)\n",
    "\n",
    "# Erreur de prévision sur le test\n",
    "print(\"Erreur de test random forest opt -quantitatif = %f\" % (1-rfOpt.score(xTest,yTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Gradient boosting*\n",
    "\n",
    "**Q** Quel est l'algorithme de *boosting* historique? Lequel est utilisé ici?\n",
    "\n",
    "**Q** Quels sont les paramètres qu'il est important de contrôler, optimiser?\n",
    "\n",
    "**Q** Quelle est la valeur par défaut de celui non optimisé ci-dessous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Optimisation de deux paramètres\n",
    "paramGrid = [\n",
    "  {'n_estimators': list(range(100,601,50)), 'learning_rate': [0.1,0.2,0.3,0.4]}\n",
    " ]\n",
    "gbmC= GridSearchCV(GradientBoostingClassifier(),paramGrid,cv=5,n_jobs=-1)\n",
    "gbmOpt=gbmC.fit(xApp, yApp)\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - gbmOpt.best_score_,gbmOpt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prévision de l'échantillon test\n",
    "yChap = gbmOpt.predict(xTest)\n",
    "# matrice de confusion\n",
    "table=pd.crosstab(yChap,yTest)\n",
    "print(table)\n",
    "\n",
    "# Erreur de prévision sur le test\n",
    "print(\"Erreur de test gbm opt = %f\" % (1-gbmOpt.score(xTest,yTest)))\n",
    "send((\"Erreur de test gbm opt = %f\" % (1-gbmOpt.score(xTest,yTest))), 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Liste des méthodes\n",
    "listMethod=[[\"Logit\",logitLasso],[\"lda\",disLin],[\"Arbre\",treeOpt],[\"RF\",rfOpt],[\"GBM\",gbmOpt]]\n",
    "# Tracé des courbes\n",
    "for method in enumerate(listMethod):\n",
    "    probas_ = method[1][1].predict_proba(xTest)\n",
    "    fpr, tpr, thresholds = roc_curve(yTest, probas_[:,1])\n",
    "    plt.plot(fpr, tpr, lw=1,label=\"%s\"%method[1][0])\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.legend(loc=\"best\")\n",
    "send(plt, 13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelles meilleure méthode interprétable? Quelle meilleure méthode?\n",
    "\n",
    "**Q** Que dire de l'*extrem gradient boosting* ? Du nombre de paramètres à optimiser? De son implémentation en Python par rapport à R? De sa disponibilité sous Windows?\n",
    "\n",
    "**Exercice** Ajouter les réseaux de neurones et les SVM dans la comparaison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Grille de valeurs du paramètre de pénalisaiton\n",
    "param = [{\"C\": [0.5, 1, 5, 10, 12, 15, 30]}] # dictionnaire de valeurs de C, utilisé pour GridSearchCV\n",
    "# TODO\n",
    "# 1. Definir le modèle (regression logistique)\n",
    "# 2. On utilisera ici une pénalité l1 penalty=\"l1\"\n",
    "# 3. Utiliser GridSearchCV pour obtenir directement le meilleur paramètre de régularisation\n",
    "# 4. On appellera la méthode logitLasso pour la suite !\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CAlculer perte\n",
    "print(\"Meilleur score (apprentissage) = %f, Meilleur paramètre = %s\" %\n",
    "      (1.-logitLasso.best_score_,logitLasso.best_params_))\n",
    "send(\"Meilleur score (apprentissage) = %f, Meilleur paramètre = %s\" %\n",
    "      (1.-logitLasso.best_score_,logitLasso.best_params_),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erreur de prévision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prévision\n",
    "yChap = logitLasso.predict(xTest)\n",
    "# TODO:  calculer la matrice de confusionen utilisant pd.crosstab\n",
    "\n",
    "print(table)\n",
    "print(\"Erreur de test régression Lasso = %f\" % (1-logitLasso.score(xTest, yTest)))\n",
    "send(\"Erreur de test régression Lasso = %f\" % (1-logitLasso.score(xTest, yTest)), 14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
